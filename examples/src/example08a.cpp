/**
 * @file example08a.cpp, example08a.hpp
 * 
 * @author Hari Sundar   hsundar@gmail.com
 * @author Han Duc Tran  hantran@cs.utah.edu
 * 
 * @brief this example to test quadratic tetrahedra element (TET10) with mesh generated by Gmsh for elasticity problem:
 * @brief (same problem of example06 & example07) solving elastic bar under its own weight
 * @brief however, instead of applying the traction BCs, we apply Diriclet BCs for displacements on all surfaces that are derived from the exact solution:
 * @brief u = -(nu * rho * g / E) * x1 * x3
 * @brief v = -(nu * rho * g / E) * x2 * x3
 * @brief w = (rh0 * g /2/E)*(x3^2 - L3^2) + (nu * rh0 * g /2/E)*(x1^2 + x2^2)
 * @brief (this example was ex7 in in aMat_for_paper/)
 * @brief For this example, we use Lx = Ly = Lz = L = 100
 * @brief The Gmsh mesh files are: ex8_quad_4p.msh (to run with -np 4)
 *                                 ex8_quad_8p.msh (to run with -np 8)
 * 
 * Note: the above exact solution is for -Lx/2 <= x <= Lx/2; -Ly/2 <= y <= Ly/2; 0 <= z <= Lz. Thus, Gmsh mesh needs to follow this setup
 * 
 * @date 2021-04-27
 */
#include "example08a.hpp"
AppData example08aAppData;

// number of cracks allowed in 1 element
#define MAX_CRACK_LEVEL 0

// max number of block dimensions in one cracked element
#define MAX_BLOCKS_PER_ELEMENT (1u << MAX_CRACK_LEVEL)

void usage()
{
    std::cout << "\n";
    std::cout << "Usage:\n";
    std::cout << "./example08a <method> <BC method> <n Streams> <meshfile> <outFile>\n";
    std::cout << "\n";
    exit(0);
}

// function to compute element matrix, used in method = 2
void computeElemMat(unsigned int eid, double* ke, double* xe) {

   GmshMesh * p_mesh = example08aAppData.p_mesh;
   unsigned int ** localMap = p_mesh->get_localMap();
   unsigned int * nNodesPerElem = p_mesh->get_nNodesPerElem();
   unsigned int nnodes = nNodesPerElem[eid];
   
   for (unsigned int n = 0; n < nnodes; n++) {
      const unsigned int localNid = localMap[eid][n];
      xe[n * 3] = p_mesh->get_x(localNid);
      xe[(n * 3) + 1] = p_mesh->get_y(localNid);
      xe[(n * 3) + 2] = p_mesh->get_z(localNid);
   }
   
   if (nnodes == 10) {
      ke_tet10_iso(ke, xe, example08aAppData.E, example08aAppData.nu, example08aAppData.intData->Pts_n_Wts, example08aAppData.NGT);
   }
   else {
      printf("error in computeElemMat function, nnodes = %d, not supported\n", nnodes);
      exit(1);
   }
   return;
}

//=============================================================================================
// function to compute displacements {u,v,w} at a node based on its coordinates {x,y,z}
// used to get prescribed values at boundary nodes; the displacements are from exact solution for this problem
void computeDispl(const double * xyz, double * uvw) {
   const double E = example08aAppData.E;
   const double nu = example08aAppData.nu;
   const double g = example08aAppData.g;
   const double rho = example08aAppData.rho;
   const double L = example08aAppData.L;
   
   uvw[0] = (-nu * rho * g)/E * xyz[0] * xyz[2]; // displacement u
   uvw[1] = (-nu * rho * g)/E * xyz[1] * xyz[2]; // displacement v
   uvw[2] = 0.5*(rho * g)/E * (xyz[2]*xyz[2] - L*L) + 0.5*(nu * rho * g)/E*(xyz[0]*xyz[0] + xyz[1]*xyz[1]); // displacement w
}

//////////////////////////////////////////////////////////////////////////////////////////////////////

int main(int argc, char* argv[]){

   double x, y, z;
   unsigned long nid, eid;

   const unsigned int NNODE_PER_ELEM = 10; // number of nodes per element
   const unsigned int NDIM = 3; // number of dimension
   const unsigned int NDOF_PER_NODE  = 3;  // number of dofs per node

   const unsigned int NDOF_PER_ELEM = NNODE_PER_ELEM * NDOF_PER_NODE;
   
   const unsigned int TRI6 = 9; // element type of boundary 6-node triangle
   const unsigned int TET10 = 11; // element type of 10-node tetrahedron
   
   const double E = 1.0E6;
   const double nu = 0.3;
   const double rho = 1.0;
   const double g = 1.0;

   typedef Eigen::Matrix<double, 30, 30> EigenMat;

   // Gauss points and weights for stiffness matrix integration (transformed to standard cube)
   // NGT is number of Gauss points in each direction
   const unsigned int NGT = 2;
   integration<double> intData(NGT);
   
   // domain sizes: L x L x L - length of the (global) domain in x, y, z direction,
   // only for computing exact solution, MUST BE THE SAME SIZE used in the Gmsh mesh
   const double L = 100.0;

   // set application data to AppData
   example08aAppData.NGT = NGT;
   example08aAppData.intData = &intData;

   example08aAppData.E = E;
   example08aAppData.nu = nu;
   example08aAppData.rho = rho;
   example08aAppData.g = g;
   example08aAppData.L = L;

   example08aAppData.NDOF_PER_NODE = NDOF_PER_NODE;
   example08aAppData.NNODE_PER_ELEM = NNODE_PER_ELEM;
   
   unsigned int matType = atoi(argv[1]); // matrix-based/aMat/matrix-free method
   unsigned int bcMethod = atoi(argv[2]); // bc method
   const unsigned int nStreams = atoi(argv[3]); // number of streams used for method 3, 4, 5
   const std::string gmshFile = argv[4]; // mesh file
   const char* filename = argv[5]; // output file

   const double zero_number = 1E-12;

   PetscInitialize(&argc, &argv, NULL, NULL);

   int rank, size;
   MPI_Comm comm = PETSC_COMM_WORLD;
   MPI_Status Stat;
   MPI_Comm_rank(comm, &rank);
   MPI_Comm_size(comm, &size);

   // output file in csv format, open in append mode
   std::ofstream outFile;
   if (rank == 0)
      outFile.open(filename, std::fstream::app);

   if (argc < 6) {
      usage();
   }

   // element matrix and vector
   EigenMat** kee;
   std::vector<Matrix<double, NNODE_PER_ELEM * NDOF_PER_NODE, 1>> fee;
   fee.resize(MAX_BLOCKS_PER_ELEMENT);

   kee = new EigenMat*[MAX_BLOCKS_PER_ELEMENT];
   for (unsigned int i = 1; i < MAX_BLOCKS_PER_ELEMENT; i++) {
      kee[i] = nullptr;
   }
   kee[0] = new EigenMat;

   // nodal coordinates of element
   double* xe = new double[NDIM * NNODE_PER_ELEM];

   // nodal body force
   double* be = new double[NDIM * NNODE_PER_ELEM];

   // timing variables
   profiler_t elem_compute_time;
   profiler_t setup_time;
   profiler_t matvec_time;
   
   elem_compute_time.clear();
   setup_time.clear();
   matvec_time.clear();

   if (!rank) {
      std::cout << "============ parameters read  =======================\n";
      std::cout << "\t\tMethod (0 = Petsc; 1 = aMat; 2 = matrix-free; 3/4/5 = GPU)= " << matType << "\n";
      std::cout << "\t\tBC method (0 = 'identity-matrix'; 1 = penalty): " << bcMethod << "\n";
      std::cout << "\t\tn streams (applied for methods 3, 4, 5)= " << nStreams << "\n";
   }

   #ifdef HYBRID_PARALLEL
   if (!rank) {
      std::cout << "\t\tHybrid parallel OpenMP + MPI\n";
      std::cout << "\t\tMax number of threads: " << omp_get_max_threads() << "\n";
      std::cout << "\t\tNumber of MPI processes: " << size << "\n";
   }
   #else
   if (!rank) {
      std::cout << "\t\tOnly MPI parallel\n";
      std::cout << "\t\tNumber of MPI processes: " << size << "\n";
   }
   #endif

   // get mesh provided by Gmsh ========================================================
   GmshMesh mesh(comm, NDOF_PER_NODE);
   mesh.setGmshMesh(gmshFile); // read text file and build local mesh
   
   unsigned int nelem_owned = mesh.get_nOwnedElems(); // number of owned elements
   printf("rank %d, number of owned elements= %d\n", rank, nelem_owned);

   unsigned int * * localDofMap = mesh.get_localDofMap(); // local dof map
   unsigned int * ndofs_per_element = mesh.get_nDofsPerElem(); // pointer to nDofsPerElem
   unsigned int numLocalDofs = mesh.get_nLocalDofs(); // local dofs = pre-ghost dofs + owned dofs + post-ghost dofs
   unsigned long * local2GlobalDofMap = mesh.get_local2GlobalDofMap(); // local to global dof id map
   unsigned long start_global_dof = mesh.get_startGlobalDof(); // start of global dof id owned by my rank
   unsigned long end_global_dof = mesh.get_endGlobalDof(); // end of global dof id owned by my rank (inclusive)
   unsigned long ndofs_total = mesh.get_nDofsTotal(); // total n dofs owned by all ranks
   unsigned int * nNodesPerElem = mesh.get_nNodesPerElem();
   unsigned int ** localMap = mesh.get_localMap(); // pointer to local map, used for getting nodal coordinates {x,y,z}

   unsigned int nConstraints = mesh.get_n_constraints(); // in fact, this is total number of boundary dofs
   printf("rank %d, number of constraints= %d\n", rank, nConstraints);
   
   unsigned long * constrainedDofs = mesh.get_constrained_dofs(); // list of global dof id of boundary dofs

   // from global id of boundary node, get its coordinates, then compute the prescribed displacement {u,v,w} using external function computeDispl
   double * prescribedValues = mesh.get_prescribed_values(&computeDispl);

   example08aAppData.p_mesh = &mesh;

   // provide Gmsh mesh to aMat ========================================================
   par::Maps<double, unsigned long, unsigned int> meshMaps(comm);
   meshMaps.set_map(nelem_owned,
                  localDofMap,
                  ndofs_per_element,
                  numLocalDofs,
                  local2GlobalDofMap,
                  start_global_dof,
                  end_global_dof,
                  ndofs_total);
   meshMaps.set_bdr_map(constrainedDofs, prescribedValues, nConstraints);

   // declare aMat object =================================
   typedef par::aMat<par::aMatBased<double, unsigned long, unsigned int>, double, unsigned long, unsigned int> aMatBased; // aMat type taking aMatBased as derived class
   typedef par::aMat<par::aMatFree<double, unsigned long, unsigned int>, double, unsigned long, unsigned int> aMatFree; // aMat type taking aMatBased as derived class

   aMatBased* stMatBased; // pointer of aMat taking aMatBased as derived
   aMatFree* stMatFree;   // pointer of aMat taking aMatFree as derived

   if (matType == 0){
      // assign stMatBased to the derived class aMatBased
      stMatBased = new par::aMatBased<double, unsigned long, unsigned int>(meshMaps, (par::BC_METH)bcMethod);
   } else {
      // assign stMatFree to the derived class aMatFree
      stMatFree = new par::aMatFree<double, unsigned long, unsigned int>(meshMaps, (par::BC_METH)bcMethod);
      stMatFree->set_matfree_type((par::MATFREE_TYPE)matType);

      #ifdef USE_GPU
      if ((matType == 3) || (matType == 4) || (matType == 5)){
         stMatFree->set_num_streams(nStreams);
      }
      #endif
   }

   // nodal value of body force
   double beN[NNODE_PER_ELEM * NDOF_PER_NODE] = { 0.0 };

   // set function to compute element matrix if using matrix-free
   if (matType == 2){
      stMatFree->set_element_matrix_function(&computeElemMat);
   }

   // create rhs, solution and exact solution vectors
   Vec rhs, out, sol_exact, error;
   par::create_vec(meshMaps, rhs);
   par::create_vec(meshMaps, out);
   par::create_vec(meshMaps, sol_exact);
   par::create_vec(meshMaps, error);

   // compute element stiffness matrix and assemble global stiffness matrix and load vector
   for (unsigned int eid = 0; eid < nelem_owned; eid++) {
      const unsigned int nnodes = nNodesPerElem[eid];
      for (unsigned int nid = 0; nid < nnodes; nid++) {
         const unsigned int localNid = localMap[eid][nid];
         xe[nid * 3]       = mesh.get_x(localNid);
         xe[(nid * 3) + 1] = mesh.get_y(localNid);
         xe[(nid * 3) + 2] = mesh.get_z(localNid);

         // const body force in z direction
         beN[(nid * NDOF_PER_NODE)]     = 0.0;
         beN[(nid * NDOF_PER_NODE) + 1] = 0.0;
         beN[(nid * NDOF_PER_NODE) + 2] = -rho * g;
      }

      // compute element stiffness matrix
      setup_time.start();
      elem_compute_time.start();
      ke_tet10_iso(*kee[0], xe, E, nu, intData.Pts_n_Wts, NGT);
      elem_compute_time.stop();

      // assemble element stiffness matrix to global K
      if (matType == 0)
         stMatBased->set_element_matrix(eid, *kee[0], 0, 0, 1);
      else
         stMatFree->set_element_matrix(eid, *kee[0], 0, 0, 1);
      setup_time.stop();

      // compute element load vector due to body force
      fe_tet10_iso(fee[0], xe, beN, intData.Pts_n_Wts, NGT);

      // assemble element load vector to global F
      par::set_element_vec(meshMaps, rhs, eid, fee[0], 0u, ADD_VALUES);
   }
   delete[] xe;
   delete[] be;

   if (matType == 0){
      setup_time.start();
      stMatBased->finalize(); // Pestc begins and completes assembling the global stiffness matrix
      setup_time.stop();
   } else {
      setup_time.start();
      stMatFree->finalize(); // compute trace of matrix when using penalty method
      setup_time.stop();
   }

   // These are needed because we used ADD_VALUES for rhs when assembling
   // now we are going to use INSERT_VALUE for Fc in apply_bc_rhs
   VecAssemblyBegin(rhs);
   VecAssemblyEnd(rhs);

   // apply bc for rhs: this must be done before applying bc for the matrix
   // because we use the original matrix to compute KfcUc in matrix-based method
   if (matType == 0)
      stMatBased->apply_bc(rhs); // this includes applying bc for matrix in matrix-based approach
   else
      stMatFree->apply_bc(rhs);

   VecAssemblyBegin(rhs);
   VecAssemblyEnd(rhs);

   // apply bc to the matrix
   if (matType == 0) {
      setup_time.start();
      stMatBased->finalize();
      setup_time.stop();
   }

   // ====================== profiling matvec ====================================
   // generate random vector of length = number of owned dofs
   /* const unsigned int numDofsTotal = meshMaps.get_NumDofsTotal();
   const unsigned int numDofs = meshMaps.get_NumDofs();

   double* X = (double*) malloc(sizeof(double) * (numDofsTotal));
   for (unsigned int i = 0; i < (numDofsTotal); i++){
      //X[i] = (double)std::rand()/(double)(RAND_MAX/5.0);
      X[i] = 1.0;
   }
   // result vector Y = [K] * X
   double* Y = (double*) malloc(sizeof(double) * (numDofsTotal));

   // total number of matvec's we want to profile
   const unsigned int num_matvecs = 10;
   if (rank == 0) printf("Number of matvecs= %d\n", num_matvecs);

   if( matType==0) {
      Vec petsc_X, petsc_Y;
      par::create_vec(meshMaps, petsc_X, 1.0);
      par::create_vec(meshMaps, petsc_Y);

      #pragma noparallel nounroll
      for (unsigned int i = 0; i < num_matvecs; i++){
         matvec_time.start();
         stMatBased->matmult(petsc_Y, petsc_X);
         matvec_time.stop();
         VecSwap(petsc_Y, petsc_X);
         VecAXPY(petsc_X,1.020,petsc_Y);
      }
      VecDestroy(&petsc_X);
      VecDestroy(&petsc_Y);

   } else {
      #pragma noparallel nounroll
      for (unsigned int i = 0; i < num_matvecs; i++){
         matvec_time.start();     
         stMatFree->matvec(Y, X, true);
         matvec_time.stop();
         std::swap(X,Y);
         // prevent compiler auto optimization
         X[0]+=0.001;
         Y[0]+=0.001;
      }
   }

   free (Y);
   free (X); */

   // ======================= solve =================================================
   matvec_time.start();
   if (matType == 0)
      par::solve(*stMatBased, (const Vec)rhs, out);
   else
      par::solve(*stMatFree, (const Vec)rhs, out);
   matvec_time.stop();
   
   //char fname[256];
   //sprintf(fname, "outVec_%d.dat", size);
   //par::dump_vec(meshMaps, out, fname);

   // ===================== finish solve =========================================
   
   // print out matrix to file
   /* if (matType == 0){
      stMatBased->dump_mat("matrix.out");
   } else {
      stMatFree->dump_mat("matrix.out");
   }
   // print out rhs to file
   par::dump_vec(meshMaps, rhs, "rhs.out"); */

   // ============================ comparing with exact solution =================
   PetscScalar norm, alpha = -1.0;

   VecNorm(out, NORM_2, &norm);
   if (!rank) {
      printf("L2 norm of computed solution = %f\n", norm);
   }

   // compute exact solution for comparison
   Matrix<double, NDOF_PER_NODE * NNODE_PER_ELEM, 1> e_exact;
   double disp[3];
   for (unsigned int eid = 0; eid < nelem_owned; eid++) {
      for (unsigned int nid = 0; nid < NNODE_PER_ELEM; nid++) {
         const unsigned int localNid = localMap[eid][nid];
         // nodal coordinates
         const double x = mesh.get_x(localNid);
         const double y = mesh.get_y(localNid);
         const double z = mesh.get_z(localNid);
         disp[0] = (-nu * rho * g)/E * x * z;
         disp[1] = (-nu * rho * g)/E * y * z;
         disp[2] =0.5*(rho * g)/E * (z*z - L*L) + 0.5*(nu * rho * g)/E*(x*x + y*y);
         for (unsigned int did = 0; did < NDOF_PER_NODE; did++) {
            e_exact[(nid * NDOF_PER_NODE) + did] = disp[did];
         }
      }
      // set exact solution to Pestc vector
      par::set_element_vec(meshMaps, sol_exact, eid, e_exact, 0u, INSERT_VALUES);
   }

   // Pestc begins and completes assembling the exact solution
   VecAssemblyBegin(sol_exact);
   VecAssemblyEnd(sol_exact);

   //sprintf(fname, "exactVec_%d.dat", size);
   //par::dump_vec(meshMaps, sol_exact, fname);

   VecNorm(sol_exact, NORM_2, &norm);
   if (!rank) {
      printf("L2 norm of exact solution = %f\n", norm);
   }
   // stMat.dump_vec("exact_vec.dat", sol_exact);
   
   // compute the error vector
   VecCopy(sol_exact, error);

   // subtract error = sol_exact - out
   VecAXPY(error, alpha, out);

   // compute norm of error
   VecNorm(error, NORM_INFINITY, &norm);

   if (rank == 0) {
      printf("L_inf norm of error = %20.10f\n", norm);
   }
   // ============================ finish comparing with exact solution ============

   // computing time acrossing ranks and display
   long double elem_compute_maxTime;
   long double setup_maxTime;
   long double matvec_maxTime;
   MPI_Reduce(&elem_compute_time.seconds, &elem_compute_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&setup_time.seconds, &setup_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&matvec_time.seconds, &matvec_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);

   if (matType == 0) {
      if (rank == 0) {
         std::cout << "(1) PETSc elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) PETSc setup time = " << setup_maxTime << "\n";
         std::cout << "(3) PETSc matvec time = " << matvec_maxTime << "\n";
         outFile << "PETSc, " << elem_compute_maxTime << "," << setup_maxTime << "," << matvec_maxTime << "\n";
      }
   } else if (matType == 1) {
      if (rank == 0) {
         std::cout << "(1) aMat-hybrid elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) aMat-hybrid setup time = "        << setup_maxTime << "\n";
         std::cout << "(3) aMat-hybrid matvec time = "       << matvec_maxTime << "\n";
         outFile << "aMat-hybrid, " << elem_compute_maxTime << ", " << setup_maxTime << ", " << matvec_maxTime << "\n";
      }
   } else if (matType == 2) {
      if (rank == 0) {
         std::cout << "(3) aMat-free matvec time = " << matvec_maxTime << "\n";
         outFile << "aMat-free, " << matvec_maxTime << "\n";
      }
   } else if ((matType == 3) || (matType == 4) || (matType == 5)) {
      if (rank == 0) {
         std::cout << "(1) aMatGpu elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) aMatGpu setup time = " << setup_maxTime << "\n";
         std::cout << "(3) aMatGpu matvec time = " << matvec_maxTime << "\n";
         outFile << "aMatGpu, " << elem_compute_maxTime << ", " << setup_maxTime << ", " << matvec_maxTime << "\n";
      }
   }
   if (rank == 0) outFile.close();
   // ===========================================================================================================

   #ifdef AMAT_PROFILER
   stMat->profile_dump(std::cout);
   #endif


   if (matType == 0) {
      delete stMatBased;
   } else {
      delete stMatFree;
   }

   // clean up Pestc vectors
   VecDestroy(&out);
   VecDestroy(&sol_exact);
   VecDestroy(&rhs);
   VecDestroy(&error);
   PetscFinalize();

   return 0;
}