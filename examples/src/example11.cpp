/**
 * @file example11.cpp, example11.hpp
 * 
 * @author Hari Sundar   hsundar@gmail.com
 * @author Han Duc Tran  hantran@cs.utah.edu
 * 
 * @brief this example to test QUADRATIC hex element (HEX27) with mesh generated by Gmsh for elasticity problem:
 * @brief (same problem of example06 & example07) solving elastic bar under its own weight
 * @brief however, instead of applying the traction BCs, we apply Diriclet BCs for displacements on all surfaces that are derived from the exact solution:
 * @brief u = -(nu * rho * g / E) * x1 * x3
 * @brief v = -(nu * rho * g / E) * x2 * x3
 * @brief w = (rh0 * g /2/E)*(x3^2 - L3^2) + (nu * rh0 * g /2/E)*(x1^2 + x2^2)
 * @brief and no body force
 * 
 * @brief For this example, we use Lx = Ly = Lz = L = 100
 * 
 * Note: the above exact solution is for -Lx/2 <= x <= Lx/2; -Ly/2 <= y <= Ly/2; 0 <= z <= Lz. Thus, Gmsh mesh needs to follow this setup
 * 
 * @date 2022-01-02
 */
#include "example11.hpp"
AppData example11AppData;

// number of cracks allowed in 1 element
#define MAX_CRACK_LEVEL 0

// max number of block dimensions in one cracked element
#define MAX_BLOCKS_PER_ELEMENT (1u << MAX_CRACK_LEVEL)

void usage() {
    std::cout << "\n";
    std::cout << "Usage:\n";
    std::cout << "./example10 <method> <BC method> <n Streams> <meshfile> <outFile>\n";
    std::cout << "\n";
    exit(0);
}

// function to compute element matrix, used in method = 2
void computeElemMat(unsigned int eid, double* ke, double* xe) {
   
   GmshMesh * p_mesh = example11AppData.p_mesh;
   unsigned int ** localMap = p_mesh->get_localMap();
   unsigned int * nNodesPerElem = p_mesh->get_nNodesPerElem();
   unsigned int nnodes = nNodesPerElem[eid];
   
   for (unsigned int n = 0; n < nnodes; n++) {
      const unsigned int localNid = localMap[eid][n];
      xe[n * 3] = p_mesh->get_x(localNid);
      xe[(n * 3) + 1] = p_mesh->get_y(localNid);
      xe[(n * 3) + 2] = p_mesh->get_z(localNid);
   }
   
   if (nnodes == 8) {
      ke_hex27_iso(ke, xe, example11AppData.E, example11AppData.nu, example11AppData.intData->Pts_n_Wts, example11AppData.NGT);
   }
   else {
      printf("computeElemMat: error in computeElemMat function, nnodes = %d, not supported\n", nnodes);
      exit(1);
   }
   return;
}

//=============================================================================================
// function to compute displacements {u,v,w} at a node based on its coordinates {x,y,z}
// used to get prescribed values at boundary nodes; the displacements are from exact solution for this problem
void computeDispl(const double * xyz, double * uvw) {
   const double E = example11AppData.E;
   const double nu = example11AppData.nu;
   const double g = example11AppData.g;
   const double rho = example11AppData.rho;
   const double Lz = example11AppData.Lz;
   
   uvw[0] = (-nu * rho * g)/E * xyz[0] * xyz[2]; // displacement u
   uvw[1] = (-nu * rho * g)/E * xyz[1] * xyz[2]; // displacement v
   uvw[2] = 0.5*(rho * g)/E * (xyz[2]*xyz[2] - Lz*Lz) + 0.5*(nu * rho * g)/E*(xyz[0]*xyz[0] + xyz[1]*xyz[1]); // displacement w
}

// An ah-hoc boundary condition: 0 displacements for all boundary nodes
void bdrDispl(const double * xyz, double * uvw) {
   uvw[0] = 0.0; // displacement u
   uvw[1] = 0.0; // displacement v
   uvw[2] = 0.0; // displacement w
}

//////////////////////////////////////////////////////////////////////////////////////////////////////

int main(int argc, char* argv[]){

   double x, y, z;
   unsigned long nid, eid;

   const unsigned int NNODE_PER_ELEM = 27; // number of nodes per element
   const unsigned int NDIM = 3; // number of dimension
   const unsigned int NDOF_PER_NODE  = 3;  // number of dofs per node

   const unsigned int NDOF_PER_ELEM = NNODE_PER_ELEM * NDOF_PER_NODE;
   
   // material properties of alumina
   // Steel: E = 207 GPa = 207E9 Pa (1Pa = 1N/m^2), nu = 0.28, rho = 8050 kg/m^3
   // Graphene: E = 1.05E12 Pa, nu = 0.186, rho = 2267 kg/m^3
   /* const double E = 1050E9;
   const double nu = 0.186;
   const double rho = 2267; */
   const double E = 1.05E12;
   const double nu = 0.186;
   const double rho = 2267;
   const double g = 9.8;
   /* const double E = 1.0;
   const double nu = 0.1;
   const double rho = 1;
   const double g = 1; */

   typedef Eigen::Matrix<double, 81, 81> EigenMat;

   // Gauss points and weights for stiffness matrix integration (transformed to standard cube)
   // NGT is number of Gauss points in each direction
   const unsigned int NGT = 2;
   integration<double> intData(NGT); 
   
   // domain sizes: L x L x L - length of the (global) domain in x, y, z direction,
   // only for computing exact solution, MUST BE THE SAME SIZE used in the Gmsh mesh
   const double Lz = 100.0;

   // set application data to AppData
   example11AppData.NGT = NGT;
   example11AppData.intData = &intData;

   example11AppData.E = E;
   example11AppData.nu = nu;
   example11AppData.rho = rho;
   example11AppData.g = g;
   example11AppData.Lz = Lz;

   example11AppData.NDOF_PER_NODE = NDOF_PER_NODE;
   example11AppData.NNODE_PER_ELEM = NNODE_PER_ELEM;
   
   unsigned int matType = atoi(argv[1]); // matrix-based/aMat/matrix-free method
   unsigned int bcMethod = atoi(argv[2]); // bc method
   const unsigned int nStreams = atoi(argv[3]); // number of streams used for method 3, 4, 5
   const std::string gmshFile = argv[4]; // mesh file 
   const char* filename = argv[5]; // output file

   PetscInitialize(&argc, &argv, NULL, NULL);

   int rank, size;
   MPI_Comm comm = PETSC_COMM_WORLD;
   MPI_Status Stat;
   MPI_Comm_rank(comm, &rank);
   MPI_Comm_size(comm, &size);

   // output file in csv format, open in append mode
   std::ofstream outFile;
   if (rank == 0)
      outFile.open(filename, std::fstream::app);

   if (argc < 6) {
      usage();
   }

   // element matrix and vector
   //double* ke = new double [NDOF_PER_ELEM * NDOF_PER_ELEM];
   EigenMat ** kee;
   kee = new EigenMat*[MAX_BLOCKS_PER_ELEMENT];
   for (unsigned int i = 1; i < MAX_BLOCKS_PER_ELEMENT; i++) {
      kee[i] = nullptr;
   }
   kee[0] = new EigenMat;

   std::vector<Matrix<double, NNODE_PER_ELEM * NDOF_PER_NODE, 1>> fee;
   fee.resize(MAX_BLOCKS_PER_ELEMENT);
   //double* fe = new double [NDOF_PER_ELEM];

   // nodal coordinates of element
   double* xe = new double[NDIM * NNODE_PER_ELEM];

   // timing variables
   profiler_t elem_compute_time;
   profiler_t setup_time;
   profiler_t matvec_time;
   profiler_t total_time;
   
   elem_compute_time.clear();
   setup_time.clear();
   matvec_time.clear();
   total_time.clear();

   if (!rank) {
      std::cout << "============ parameters read  =======================\n";
      std::cout << "\t\tMethod (0 = Petsc; 1 = aMat; 2 = matrix-free; 3/4/5 = GPU)= " << matType << "\n";
      std::cout << "\t\tBC method (0 = 'identity-matrix'; 1 = penalty): " << bcMethod << "\n";
      std::cout << "\t\tn streams (applied for methods 3, 4, 5)= " << nStreams << "\n";
   }

   #ifdef HYBRID_PARALLEL
   if (!rank) {
      std::cout << "\t\tHybrid parallel OpenMP + MPI\n";
      std::cout << "\t\tMax number of threads: " << omp_get_max_threads() << "\n";
      std::cout << "\t\tNumber of MPI processes: " << size << "\n";
   }
   #else
   if (!rank) {
      std::cout << "\t\tOnly MPI parallel\n";
      std::cout << "\t\tNumber of MPI processes: " << size << "\n";
   }
   #endif

   // get mesh provided by Gmsh ========================================================
   GmshMesh mesh(comm, NDOF_PER_NODE); //TODO: change it to pointer to GmshMesh so that we can delete to free memory occupied
   mesh.setGmshMesh(gmshFile); // read text file and build local mesh

   unsigned int nelem_owned = mesh.get_nOwnedElems(); // number of owned elements
   printf("rank %d, number of owned elements= %d\n", rank, nelem_owned);

   unsigned int * * localDofMap = mesh.get_localDofMap(); // local dof map
   unsigned int * ndofs_per_element = mesh.get_nDofsPerElem(); // pointer to nDofsPerElem
   unsigned int numLocalDofs = mesh.get_nLocalDofs();
   unsigned long * local2GlobalDofMap = mesh.get_local2GlobalDofMap(); // local to global dof id map
   unsigned long start_global_dof = mesh.get_startGlobalDof(); // start of global dof id owned by my rank
   unsigned long end_global_dof = mesh.get_endGlobalDof(); // end of global dof id owned by my rank (inclusive)
   unsigned long ndofs_total = mesh.get_nDofsTotal(); // total n dofs owned by all ranks
   printf("rank %d, number of dofs owned by all ranks= %d\n", rank, ndofs_total);
   unsigned int * nNodesPerElem = mesh.get_nNodesPerElem();
   unsigned int ** localMap = mesh.get_localMap(); // pointer to local map, used for getting nodal coordinates {x,y,z}

   unsigned int nConstraints = mesh.get_n_constraints(); // in fact, this is total number of boundary dofs
   printf("rank %d, number of constraints= %d\n", rank, nConstraints);
   
   unsigned long * constrainedDofs = mesh.get_constrained_dofs(); // list of global dof id of boundary dofs

   // from global id of boundary node, get its coordinates, then compute the prescribed displacement {u,v,w} using external function computeDispl
   double * prescribedValues = mesh.get_prescribed_values(&computeDispl);

   example11AppData.p_mesh = &mesh; // pass pointer of mesh to external example11AppData

   // provide Gmsh mesh to aMat ========================================================
   par::Maps<double, unsigned long, unsigned int> meshMaps(comm); // maps used by aMat
   meshMaps.set_map(nelem_owned, 
                  localDofMap, 
                  ndofs_per_element, 
                  numLocalDofs,
                  local2GlobalDofMap,
                  start_global_dof,
                  end_global_dof,
                  ndofs_total);
   meshMaps.set_bdr_map(constrainedDofs, prescribedValues, nConstraints);

   // declare aMat object =================================
   typedef par::aMat<par::aMatBased<double, unsigned long, unsigned int>, double, unsigned long, unsigned int> aMatBased; // aMat type taking aMatBased as derived class
   typedef par::aMat<par::aMatFree<double, unsigned long, unsigned int>, double, unsigned long, unsigned int> aMatFree; // aMat type taking aMatBased as derived class

   aMatBased* stMatBased; // pointer of aMat taking aMatBased as derived
   aMatFree* stMatFree;   // pointer of aMat taking aMatFree as derived

   if (matType == 0){
      // assign stMatBased to the derived class aMatBased
      stMatBased = new par::aMatBased<double, unsigned long, unsigned int>(meshMaps, (par::BC_METH)bcMethod);
   } else {
      // assign stMatFree to the derived class aMatFree
      stMatFree = new par::aMatFree<double, unsigned long, unsigned int>(meshMaps, (par::BC_METH)bcMethod);
      stMatFree->set_matfree_type((par::MATFREE_TYPE)matType);

      #ifdef USE_GPU
      if ((matType == 3) || (matType == 4) || (matType == 5)){
         stMatFree->set_num_streams(nStreams);
      }
      #endif
   }

   // nodal value of body force
   double beN[NNODE_PER_ELEM * NDOF_PER_NODE] = { 0.0 };

   // set function to compute element matrix if using matrix-free
   if (matType == 2){
      stMatFree->set_element_matrix_function(&computeElemMat);
   }

   // create rhs, solution and exact solution vectors
   Vec rhs, out, sol_exact, error;
   par::create_vec(meshMaps, rhs);
   par::create_vec(meshMaps, out);
   par::create_vec(meshMaps, sol_exact);
   par::create_vec(meshMaps, error);

   // compute element stiffness matrix and assemble global stiffness matrix and load vector
   total_time.start();
   for (unsigned int eid = 0; eid < nelem_owned; eid++) {
      const unsigned int nnodes = nNodesPerElem[eid];
      for (unsigned int nid = 0; nid < nnodes; nid++) {
         const unsigned int localNid = localMap[eid][nid];
         xe[nid * 3]       = mesh.get_x(localNid);
         xe[(nid * 3) + 1] = mesh.get_y(localNid);
         xe[(nid * 3) + 2] = mesh.get_z(localNid);

         // const body force in z direction
         beN[(nid * NDOF_PER_NODE)]     = 0.0;
         beN[(nid * NDOF_PER_NODE) + 1] = 0.0;
         //beN[(nid * NDOF_PER_NODE) + 2] = -rho * g;
         beN[(nid * NDOF_PER_NODE) + 2] = 0.0;
      }

      // compute element stiffness matrix
      setup_time.start();
      elem_compute_time.start();
      ke_hex27_iso(*kee[0], xe, E, nu, intData.Pts_n_Wts, NGT);
      elem_compute_time.stop();
      
      // assemble element stiffness matrix to global K
      if (matType == 0)
         stMatBased->set_element_matrix(eid, *kee[0], 0, 0, 1);
      else
         stMatFree->set_element_matrix(eid, *kee[0], 0, 0, 1);
      setup_time.stop();

      // compute element load vector due to body force
      fe_hex27_iso(fee[0], xe, beN, intData.Pts_n_Wts, NGT);

      // assemble element load vector to global F
      par::set_element_vec(meshMaps, rhs, eid, fee[0], 0u, ADD_VALUES);
   }
   delete [] xe;

   setup_time.start();
   if (matType == 0){
      stMatBased->finalize(); // Pestc begins and completes assembling the global stiffness matrix
      
   } else {
      stMatFree->finalize(); // compute trace of matrix when using penalty method; for GPU options: transfer element matrices to gpu
   }
   setup_time.stop();

   // These are needed because we used ADD_VALUES for rhs when assembling
   // now we are going to use INSERT_VALUE for Fc in apply_bc_rhs
   VecAssemblyBegin(rhs);
   VecAssemblyEnd(rhs);

   // apply bc for rhs: this must be done before applying bc for the matrix
   // because we use the original matrix to compute KfcUc in matrix-based method
   //setup_time.start();
   if (matType == 0)
      stMatBased->apply_bc(rhs); // this includes applying bc for matrix in matrix-based approach
   else
      stMatFree->apply_bc(rhs);
   //setup_time.stop();

   VecAssemblyBegin(rhs);
   VecAssemblyEnd(rhs);
   

   /* PetscScalar norm_rhs;
   VecNorm(rhs, NORM_2, &norm_rhs);
   if (rank == 0 )printf("rhs norm= %f\n",norm_rhs); */

   // apply bc to the matrix
   if (matType == 0) {
      setup_time.start();
      stMatBased->finalize();
      setup_time.stop();
   }
   

   // ====================== profiling matvec ====================================
   // generate random vector of length = number of owned dofs
   const unsigned int numDofsTotal = meshMaps.get_NumDofsTotal();
   const unsigned int numDofs = meshMaps.get_NumDofs();

   double* X = (double*) malloc(sizeof(double) * (numDofsTotal));
   for (unsigned int i = 0; i < (numDofsTotal); i++){
      //X[i] = (double)std::rand()/(double)(RAND_MAX/5.0);
      X[i] = 1.0;
   }
   // result vector Y = [K] * X
   double* Y = (double*) malloc(sizeof(double) * (numDofsTotal));

   // total number of matvec's we want to profile
   const unsigned int num_matvecs = 50;
   if (rank == 0) printf("Number of matvecs= %d\n", num_matvecs);

   if( matType == 0) {
      Vec petsc_X, petsc_Y;
      par::create_vec(meshMaps, petsc_X, 1.0);
      par::create_vec(meshMaps, petsc_Y);

      for (unsigned int i = 0; i < num_matvecs; i++){
         matvec_time.start();
         stMatBased->matmult(petsc_Y, petsc_X);
         //VecAssemblyBegin(petsc_X);
         //VecAssemblyEnd(petsc_X);
         matvec_time.stop();
         VecSwap(petsc_Y, petsc_X);

         // this is added on May 26, 2021, following ex6
         VecAXPY(petsc_X,1.020,petsc_Y);
      }
      VecDestroy(&petsc_X);
      VecDestroy(&petsc_Y);

   } else {
      /* #ifdef USE_GPU
         #ifdef HYBRID_PARALLEL
               if (matType == 3) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_gpuHybrid_pureGpu(Y, X); // all (depend + indep) elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               } else if (matType == 4) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_gpuHybrid_gpuOverCpu(Y, X); // indep elements on gpu, depend elements on cpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               } else if (matType == 5) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_gpuHybrid_gpuOverGpu(Y, X); // indep elements on gpu, depend elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               }
         #else
               printf("Gpu matvec with pure MPI is not implemented yet\n");
               exit(1);
         #endif
      #else
         #ifdef HYBRID_PARALLEL
               if (matType == 1) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_cpuHybrid(Y, X); // all (depend + indep) elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               } else if (matType == 2) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_cpuHybrid_matFree(Y, X); // all (depend + indep) elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               }
         #else
               if (matType == 1) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_cpuPureMpi(Y, X); // all (depend + indep) elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               } else if (matType == 2) {
                  for (unsigned int i = 0; i < num_matvecs; i++){
                     matvec_time.start();     
                     stMatFree->matvec_cpuPureMpi_matFree(Y, X); // all (depend + indep) elements on gpu
                     matvec_time.stop();
                     std::swap(X,Y);
                     X[0]+=0.001;
                     Y[0]+=0.001;
                  }
               }
         #endif
      #endif */
      #pragma noparallel nounroll
      for (unsigned int i = 0; i < num_matvecs; i++){
         matvec_time.start();     
         stMatFree->matvec(Y, X, true);
         matvec_time.stop();
         std::swap(X,Y);
         // prevent compiler auto optimization
         X[0]+=0.001;
         Y[0]+=0.001;
      }
   }
   free (Y);
   free (X);

   // ======================= solve =================================================
   /* matvec_time.start();
   if (matType == 0)
      par::solve(*stMatBased, (const Vec)rhs, out);
   else
      par::solve(*stMatFree, (const Vec)rhs, out);
   matvec_time.stop();
   total_time.stop();

   //char fname[256];
   //sprintf(fname, "outVec_%d.dat", size);
   //par::dump_vec(meshMaps, out, fname);

   // ===================== finish solve =========================================
   
   // print out matrix to file
   // if (matType == 0){
   //    stMatBased->dump_mat("matrix.out");
   // } else {
   //    stMatFree->dump_mat("matrix.out");
   // }
   // // print out rhs to file
   // par::dump_vec(meshMaps, rhs, "rhs.out");

   // ============================ comparing with exact solution =================
   PetscScalar norm, alpha = -1.0;

   VecNorm(out, NORM_2, &norm);
   if (!rank) {
      printf("L2 norm of computed solution = %f\n", norm);
   }

   // compute exact solution for comparison
   //double* e_exact = new double [NDOF_PER_ELEM];
   Matrix<double, NDOF_PER_NODE * NNODE_PER_ELEM, 1> e_exact;

   double disp[3];
   for (unsigned int eid = 0; eid < nelem_owned; eid++) {
      for (unsigned int nid = 0; nid < NNODE_PER_ELEM; nid++) {
         const unsigned int localNid = localMap[eid][nid];
         // nodal coordinates
         const double x = mesh.get_x(localNid);
         const double y = mesh.get_y(localNid);
         const double z = mesh.get_z(localNid);
         disp[0] = (-nu * rho * g)/E * x * z;
         disp[1] = (-nu * rho * g)/E * y * z;
         disp[2] =0.5*(rho * g)/E * (z*z - Lz*Lz) + 0.5*(nu * rho * g)/E*(x*x + y*y);
         for (unsigned int did = 0; did < NDOF_PER_NODE; did++) {
            e_exact[(nid * NDOF_PER_NODE) + did] = disp[did];
         }
      }
      // set exact solution to Pestc vector
      par::set_element_vec(meshMaps, sol_exact, eid, e_exact, 0u, INSERT_VALUES);
   }
   //delete [] e_exact;

   // Pestc begins and completes assembling the exact solution
   VecAssemblyBegin(sol_exact);
   VecAssemblyEnd(sol_exact);

   //sprintf(fname, "exactVec_%d.dat", size);
   //par::dump_vec(meshMaps, sol_exact, fname);

   VecNorm(sol_exact, NORM_2, &norm);
   if (!rank) {
      printf("L2 norm of exact solution = %f\n", norm);
   }
   // stMat.dump_vec("exact_vec.dat", sol_exact);
   
   // compute the error vector
   VecCopy(sol_exact, error);

   // subtract error = sol_exact - out
   VecAXPY(error, alpha, out);

   // compute norm of error
   VecNorm(error, NORM_INFINITY, &norm);

   if (rank == 0) {
      printf("L_inf norm of error = %20.10f\n", norm);
   } */

   long double gather_time, scatter_time, mv_time, mvTotal_time;
   if ((matType == 3) || (matType == 4) || (matType == 5)) {
      stMatFree->get_timer(&scatter_time, &gather_time, &mv_time, &mvTotal_time);
   } 
   // ============================ finish comparing with exact solution ============

   // computing time acrossing ranks and display
   long double elem_compute_maxTime;
   long double setup_maxTime;
   long double matvec_maxTime;
   long double total_maxTime;
   long double gather_maxTime, scatter_maxTime, mv_maxTime, mvTotal_maxTime;

   MPI_Reduce(&elem_compute_time.seconds, &elem_compute_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&setup_time.seconds, &setup_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&matvec_time.seconds, &matvec_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   //MPI_Reduce(&total_time.seconds, &total_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&gather_time, &gather_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&scatter_time, &scatter_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&mv_time, &mv_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);
   MPI_Reduce(&mvTotal_time, &mvTotal_maxTime, 1, MPI_LONG_DOUBLE, MPI_MAX, 0, comm);

   if (matType == 0) {
      if (rank == 0) {
         std::cout << "(1) PETSc elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) PETSc setup time = " << setup_maxTime << "\n";
         std::cout << "(3) PETSc matvec time = " << matvec_maxTime << "\n";
         //std::cout << "(4) PETSc total time = " << total_maxTime << "\n";
         outFile << "PETSc, " << elem_compute_maxTime << "," << setup_maxTime << "," << matvec_maxTime << "\n";
         //outFile << "PETSc, " << matvec_maxTime << "," << total_maxTime << "\n";
         //outFile << "PETSc, " << setup_maxTime << "," << matvec_maxTime << "\n";
      }
   } else if (matType == 1) {
      if (rank == 0) {
         std::cout << "(1) aMat-hybrid elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) aMat-hybrid setup time = "        << setup_maxTime << "\n";
         std::cout << "(3) aMat-hybrid matvec time = "       << matvec_maxTime << "\n";
         //std::cout << "(4) aMat-hybrid total time = "       << total_maxTime << "\n";
         outFile << "aMat-hybrid, " << elem_compute_maxTime << ", " << setup_maxTime << ", " << matvec_maxTime << "\n";
         //outFile << "aMat, " << matvec_maxTime << ", " << total_maxTime << "\n";
         //outFile << "aMat, " << setup_maxTime << ", " << matvec_maxTime << "\n";
      }
   } else if (matType == 2) {
      if (rank == 0) {
         std::cout << "(3) aMat-free matvec time = " << matvec_maxTime << "\n";
         //std::cout << "(4) aMat-free total time = " << total_maxTime << "\n";
         outFile << "aMat-free, " << matvec_maxTime << "\n";
         //outFile << "aMat-free, " << matvec_maxTime  << "," << total_maxTime << "\n";
         //outFile << "aMat-free, " << matvec_maxTime  << "\n";
      }
   } else if ((matType == 3) || (matType == 4) || (matType == 5)) {
      if (rank == 0) {
         std::cout << "(1) aMatGpu elem compute time = " << elem_compute_maxTime << "\n";
         std::cout << "(2) aMatGpu setup time = " << setup_maxTime << "\n";
         std::cout << "(3) aMatGpu matvec time = " << matvec_maxTime << "\n";
         //std::cout << "(4) aMatGpu total time = " << total_maxTime << "\n";
         std::cout << "(4) aMatGpu (scatter, gather, mv, mvTotal) time = " << scatter_maxTime << ", " << gather_maxTime << ", " << mv_maxTime << ", " << mvTotal_maxTime << "\n";
         outFile << "aMatGpu, " << elem_compute_maxTime << ", " << setup_maxTime << ", " << matvec_maxTime << "\n";
         //outFile << "aMatGpu, " << matvec_maxTime << ", " << total_maxTime << "\n";
         //outFile << "aMatGpu, " << setup_maxTime << ", " << matvec_maxTime << "\n";
      }
   }
   if (rank == 0) outFile.close();
   // ===========================================================================================================
   // export ParaView
   /* std::ofstream myfile;
   char fname[256];
   sprintf(fname, "ex10_%d_%d.vtk", rank, size);
   unsigned int nnodes_local = mesh.get_nLocalNodes(); // number of local dofs
   unsigned long * local2GlobalMap = mesh.get_local2GlobalMap();
   
   myfile.open(fname);
   myfile << "# vtk DataFile Version 2.0 " << std::endl;
   myfile << "Stress field" << std::endl;
   myfile << "ASCII" << std::endl;
   myfile << "DATASET UNSTRUCTURED_GRID" << std::endl;
   myfile << "POINTS " << nnodes_local << " float" << std::endl;
   for (unsigned int nid = 0; nid < nnodes_local; nid++) {
      const double x = mesh.get_x(nid);
      const double y = mesh.get_y(nid);
      const double z = mesh.get_z(nid);
      myfile << x << "  " << y << "  " << z << std::endl;
   }
   unsigned int size_cell_list = nelem_owned * 9;
   myfile << "CELLS " << nelem_owned << " " << size_cell_list << std::endl;
   for (unsigned int eid = 0; eid < nelem_owned; eid++){
      myfile << "8 " << localMap[eid][0] << " " << localMap[eid][1] << " "
         << localMap[eid][2] << " " << localMap[eid][3] << " "
         << localMap[eid][4] << " " << localMap[eid][5] << " "
         << localMap[eid][6] << " " << localMap[eid][7] << std::endl;
   }
   myfile << "CELL_TYPES " << nelem_owned << std::endl;
   for (unsigned int eid = 0; eid < nelem_owned; eid++){
      myfile << "12" << std::endl;
   } */
   /* myfile << "POINT_DATA " << nnodes_local << std::endl;
   myfile << "VECTORS " << "displacement " << "float " << std::endl;
   std::vector<PetscInt> indices (NDOF_PER_NODE);
   std::vector<PetscScalar> values (NDOF_PER_NODE);
   for (unsigned int nid = 0; nid < nnodes_local; nid++){
      const unsigned long gNodeId = local2GlobalMap[nid];
      for (unsigned int did = 0; did < NDOF_PER_NODE; did++){
            indices[did] = gNodeId * NDOF_PER_NODE + did;
      }
      VecGetValues(out, NDOF_PER_NODE, indices.data(), values.data());
      myfile << values[0] << " " << values[1] << " " << values[2] << std::endl;
   } */
   //myfile.close();
   
   // ===========================================================================================================

   #ifdef AMAT_PROFILER
   if (matType == 0) {
      stMatBased->profile_dump(std::cout);
   } else {
      stMatFree->profile_dump(std::cout);
   }
   #endif


   if (matType == 0) {
      delete stMatBased;
   } else {
      delete stMatFree;
   }

   // clean up Pestc vectors
   VecDestroy(&out);
   VecDestroy(&sol_exact);
   VecDestroy(&rhs);
   VecDestroy(&error);

   PetscFinalize();

   return 0;
}